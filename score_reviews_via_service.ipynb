{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Existing Machine Learning Services\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/peckjon/hosting-ml-as-microservice/blob/master/part1/score_reviews_via_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain labelled reviews\n",
    "\n",
    "In order to test any of the sentiment analysis APIs, we need a labelled dataset of reviews and their sentiment polarity. We'll use NLTK to download the movie_reviews corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\coolemi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download\n",
    "\n",
    "download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add requred additional libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import math\n",
    "from pytictoc import TicToc\n",
    "t = TicToc() #create instance of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'Out',\n",
       " 'TicToc',\n",
       " '_',\n",
       " '_1',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i2',\n",
       " '_i3',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'boto3',\n",
       " 'download',\n",
       " 'exit',\n",
       " 'get_ipython',\n",
       " 'quit',\n",
       " 't']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "The files in movie_reviews have already been divided into two sets: positive ('pos') and negative ('neg'), so we can load the raw text of the reviews into two lists, one for each polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 0.865447 seconds.\n"
     ]
    }
   ],
   "source": [
    "# extract words from reviews, pair with label\n",
    "t.tic()\n",
    "\n",
    "reviews_pos = []\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    review = movie_reviews.raw(fileid)\n",
    "    reviews_pos.append(review)\n",
    "\n",
    "reviews_neg = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    review = movie_reviews.raw(fileid)\n",
    "    reviews_neg.append(review)\n",
    "    \n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the scoring API\n",
    "\n",
    "Fill in this function with code that connects to one of these APIs, and uses it to score a single review:\n",
    "\n",
    "* [Amazon Comprehend: Detect Sentiment](https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectSentiment.html)\n",
    "* [Google Natural Language: Analyzing Sentiment](https://cloud.google.com/natural-language/docs/analyzing-sentiment)\n",
    "* [Azure Cognitive Services: Sentiment Analysis](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-sentiment-analysis)\n",
    "* [Algorithmia: Sentiment Analysis](https://algorithmia.com/algorithms/nlp/SentimentAnalysis)\n",
    "\n",
    "Your function must return either 'pos' or 'neg', so you'll need to make some decisions about how to map the results of the API call to one of these values. For example, Amazon Comprehend can return \"NEUTRAL\" or \"MIXED\" for the Sentiment -- if this happens, you may with to inspect the numeric values under the SentimentScore to see whether it leans toward positive or negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the reviews individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_review(review):\n",
    "    \n",
    "    # establish an AWS session with a profile with permission to access \"comprehend\"\n",
    "    session = boto3.Session(profile_name='ml-as-microservice')\n",
    "    \n",
    "    # establish a client variable to access the \"comprehend\" service\n",
    "    comp = session.client(service_name='comprehend')\n",
    "    \n",
    "    # store the model's output of the review in a variable\n",
    "    model_output = comp.detect_sentiment(Text = review, LanguageCode='en')\n",
    "    \n",
    "    # get the positive probability, and the negative probability\n",
    "    pos = model_output['SentimentScore']['Positive']\n",
    "    neg = model_output['SentimentScore']['Negative']\n",
    "    \n",
    "    # if positive is more probable, give pos.  Else, give neg.\n",
    "    if pos > neg:\n",
    "        function_output = 'pos'\n",
    "    else:\n",
    "        function_output = 'neg'\n",
    "        \n",
    "    return function_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score each review\n",
    "\n",
    "Now, we can use the function you defined to score each of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "\n",
    "results_pos = []\n",
    "for review in reviews_pos:\n",
    "    result = score_review(review[0:5000])\n",
    "    results_pos.append(result)\n",
    "\n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tic()\n",
    "\n",
    "results_neg = []\n",
    "for review in reviews_neg:\n",
    "    result = score_review(review[0:5000])\n",
    "    results_neg.append(result)\n",
    "\n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.floor(1000/25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the reviews batch-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_review_batch(review_list):\n",
    "    # establish an AWS session with a profile with permission to access \"comprehend\"\n",
    "    session = boto3.Session(profile_name='ml-as-microservice')\n",
    "    \n",
    "    # establish a client variable to access the \"comprehend\" service\n",
    "    comp = session.client(service_name='comprehend')\n",
    "\n",
    "    # no elements longer than 5k\n",
    "    review_list[:] = (elem[0:4999] for elem in review_list)\n",
    "    \n",
    "    # initialize the list that will hold the results\n",
    "    sentiment_list = []\n",
    "    \n",
    "    # batch will only receive 25 at a time.  loop through the list in sets of 25\n",
    "    i = 0\n",
    "    max_i = math.floor(len(review_list)/25)-1\n",
    "    \n",
    "    while i <= max_i:\n",
    "    \n",
    "        ndx_min = i*25\n",
    "        ndx_max = min(ndx_min + 24, len(review_list))\n",
    "        \n",
    "        # print('from ', ndx_min, ' to ', ndx_max)\n",
    "    \n",
    "        # create a list of the model's sentiment scores for each review in the review list\n",
    "        full_review_list = comp.batch_detect_sentiment(TextList = review_list[ndx_min:ndx_max], LanguageCode='en')['ResultList']\n",
    "\n",
    "        # calc a 'pos' or 'neg' for each element of the full_review_list\n",
    "        for ele in full_review_list:\n",
    "            if ele['SentimentScore']['Positive'] > ele['SentimentScore']['Negative']:\n",
    "                result = 'pos'\n",
    "            else:\n",
    "                result = 'neg'\n",
    "            sentiment_list.append(result)\n",
    "        \n",
    "        i = i+1\n",
    "\n",
    "    return sentiment_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score each review\n",
    "\n",
    "Now, we can use the function you defined to score each of the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 27.851296 seconds.\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "results_pos = score_review_batch(reviews_pos)\n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 26.216157 seconds.\n"
     ]
    }
   ],
   "source": [
    "t.tic()\n",
    "results_neg = score_review_batch(reviews_neg)\n",
    "t.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate accuracy\n",
    "\n",
    "For each of our known positive reviews, we can count the number which our function scored as 'pos', and use this to calculate the % accuracy. We repeaty this for negative reviews, and also for overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 75.52083333333334% correct\n",
      "Negative reviews: 56.875% correct\n",
      "Overall accuracy: 66.19791666666667% correct\n"
     ]
    }
   ],
   "source": [
    "correct_pos = results_pos.count('pos')\n",
    "accuracy_pos = float(correct_pos) / len(results_pos)\n",
    "correct_neg = results_neg.count('neg')\n",
    "accuracy_neg = float(correct_neg) / len(results_neg)\n",
    "correct_all = correct_pos + correct_neg\n",
    "accuracy_all = float(correct_all) / (len(results_pos)+len(results_neg))\n",
    "\n",
    "print('Positive reviews: {}% correct'.format(accuracy_pos*100))\n",
    "print('Negative reviews: {}% correct'.format(accuracy_neg*100))\n",
    "print('Overall accuracy: {}% correct'.format(accuracy_all*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
